{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.Module and torch.nn.Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      " Model params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0775, -0.0466, -0.0823,  ...,  0.0309,  0.0463,  0.0428],\n",
      "        [-0.0781, -0.0686,  0.0975,  ..., -0.0794,  0.0393,  0.0911],\n",
      "        [ 0.0742,  0.0978,  0.0943,  ..., -0.0161, -0.0011, -0.0035],\n",
      "        ...,\n",
      "        [ 0.0099, -0.0698, -0.0138,  ...,  0.0255, -0.0374,  0.0363],\n",
      "        [-0.0115,  0.0733,  0.0282,  ..., -0.0817,  0.0057,  0.0434],\n",
      "        [-0.0293, -0.0277,  0.0653,  ...,  0.0476,  0.0951,  0.0572]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0904, -0.0416,  0.0679,  0.0950, -0.0284,  0.0648, -0.0184, -0.0779,\n",
      "         0.0393, -0.0329,  0.0526,  0.0494, -0.0908, -0.0234,  0.0896, -0.0008,\n",
      "        -0.0685, -0.0806,  0.0136, -0.0624,  0.0388,  0.0772, -0.0609,  0.0918,\n",
      "         0.0619,  0.0135, -0.0456,  0.0971,  0.0808,  0.0952, -0.0370, -0.0739,\n",
      "        -0.0572,  0.0632,  0.0365,  0.0006, -0.0638,  0.0393, -0.0418,  0.0371,\n",
      "         0.0798,  0.0457,  0.0631,  0.0712,  0.0478,  0.0899, -0.0481,  0.0395,\n",
      "        -0.0638,  0.0612, -0.0618,  0.0030,  0.0087,  0.0477,  0.0497, -0.0838,\n",
      "        -0.0589,  0.0896,  0.0258, -0.0047, -0.0230, -0.0777,  0.0877, -0.0586,\n",
      "        -0.0320,  0.0490,  0.0735,  0.0618,  0.0957, -0.0135, -0.0677,  0.0795,\n",
      "        -0.0895,  0.0359,  0.0576, -0.0618,  0.0281, -0.0227, -0.0612,  0.0965,\n",
      "        -0.0098, -0.0538,  0.0531, -0.0139,  0.0936, -0.0555, -0.0728,  0.0361,\n",
      "        -0.0770,  0.0713, -0.0722, -0.0552,  0.0804, -0.0890, -0.0994,  0.0475,\n",
      "        -0.0933, -0.0025,  0.0977, -0.0492, -0.0752,  0.0484, -0.0343,  0.0431,\n",
      "        -0.0794,  0.0931, -0.0732, -0.0881,  0.0784,  0.0194,  0.0032,  0.0543,\n",
      "        -0.0392, -0.0492, -0.0233, -0.0766, -0.0091,  0.0344,  0.0949,  0.0331,\n",
      "         0.0267,  0.0677,  0.0942, -0.0600, -0.0201,  0.0303,  0.0118, -0.0541,\n",
      "        -0.0527, -0.0120,  0.0410, -0.0775,  0.0462, -0.0318,  0.0956,  0.0837,\n",
      "         0.0332, -0.0740, -0.0410,  0.0040, -0.0497,  0.0631, -0.0625, -0.0515,\n",
      "        -0.0111,  0.0615, -0.0112, -0.0773, -0.0207,  0.0277, -0.0827,  0.0511,\n",
      "         0.0984,  0.0722, -0.0800,  0.0457, -0.0171,  0.0228,  0.0991,  0.0638,\n",
      "        -0.0756,  0.0966,  0.0602, -0.0833,  0.0826, -0.0433,  0.0920,  0.0101,\n",
      "         0.0233, -0.0493, -0.0966,  0.0605, -0.0668, -0.0872,  0.0845,  0.0716,\n",
      "        -0.0418, -0.0872,  0.0040,  0.0308, -0.0300, -0.0605,  0.0051, -0.0549,\n",
      "        -0.0430,  0.0873, -0.0852,  0.0222, -0.0569,  0.0475, -0.0390,  0.0803,\n",
      "         0.0672,  0.0667, -0.0470, -0.0766, -0.0445,  0.0156, -0.0065, -0.0740],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0514,  0.0346,  0.0223,  ...,  0.0496,  0.0682,  0.0389],\n",
      "        [-0.0318,  0.0193,  0.0550,  ...,  0.0581,  0.0680,  0.0691],\n",
      "        [-0.0566,  0.0114,  0.0029,  ...,  0.0122,  0.0477,  0.0160],\n",
      "        ...,\n",
      "        [ 0.0212, -0.0044,  0.0394,  ..., -0.0490, -0.0496,  0.0435],\n",
      "        [ 0.0306,  0.0659,  0.0386,  ..., -0.0066, -0.0569,  0.0314],\n",
      "        [ 0.0609,  0.0331,  0.0290,  ...,  0.0273, -0.0180,  0.0681]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0379, -0.0002, -0.0136,  0.0586,  0.0695,  0.0430,  0.0574,  0.0036,\n",
      "        -0.0153, -0.0383], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0514,  0.0346,  0.0223,  ...,  0.0496,  0.0682,  0.0389],\n",
      "        [-0.0318,  0.0193,  0.0550,  ...,  0.0581,  0.0680,  0.0691],\n",
      "        [-0.0566,  0.0114,  0.0029,  ...,  0.0122,  0.0477,  0.0160],\n",
      "        ...,\n",
      "        [ 0.0212, -0.0044,  0.0394,  ..., -0.0490, -0.0496,  0.0435],\n",
      "        [ 0.0306,  0.0659,  0.0386,  ..., -0.0066, -0.0569,  0.0314],\n",
      "        [ 0.0609,  0.0331,  0.0290,  ...,  0.0273, -0.0180,  0.0681]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0379, -0.0002, -0.0136,  0.0586,  0.0695,  0.0430,  0.0574,  0.0036,\n",
      "        -0.0153, -0.0383], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\n Model params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Layer Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0.7104, 0.3575, 0.1890]])\n",
      "\n",
      "\n",
      "Weight and Bias parameters:\n",
      "Parameter containing:\n",
      "tensor([[-0.3872,  0.4567, -0.2395],\n",
      "        [ 0.2752,  0.2803,  0.5092]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0759, -0.1720], requires_grad=True)\n",
      "\n",
      "\n",
      "Output:\n",
      "tensor([[-0.0812,  0.2199]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = torch.nn.Linear(3, 2)\n",
    "x = torch.rand(1, 3)\n",
    "print('Input:')\n",
    "print(x)\n",
    "\n",
    "print('\\n\\nWeight and Bias parameters:')\n",
    "for param in lin.parameters():\n",
    "    print(param)\n",
    "\n",
    "y = lin(x)\n",
    "print('\\n\\nOutput:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, target_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Layers and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4545, 0.4162, 0.0879, 0.7534, 0.7398, 0.3373],\n",
      "         [0.5692, 0.1075, 0.3703, 0.2151, 0.5996, 0.6495],\n",
      "         [0.2021, 0.5432, 0.9811, 0.2394, 0.3459, 0.3853],\n",
      "         [0.8899, 0.5216, 0.1839, 0.9940, 0.1797, 0.4341],\n",
      "         [0.5699, 0.1267, 0.6560, 0.3339, 0.8537, 0.1195],\n",
      "         [0.4487, 0.6072, 0.3675, 0.7267, 0.7438, 0.0321]]])\n",
      "tensor([[[0.9811, 0.7534],\n",
      "         [0.8899, 0.9940]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 6, 6)\n",
    "print(my_tensor)\n",
    "\n",
    "maxpool_layer = torch.nn.MaxPool2d(3)\n",
    "print(maxpool_layer(my_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[11.8127, 20.7439, 11.2504, 17.9157],\n",
      "         [16.5257, 11.3992,  7.6493, 15.3131],\n",
      "         [ 7.6376, 10.0736,  8.2986,  9.7116],\n",
      "         [24.6445,  7.0725, 15.7648, 24.9847]]])\n",
      "tensor(13.7999)\n",
      "BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(-1.7881e-07, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
    "print(my_tensor)\n",
    "\n",
    "print(my_tensor.mean())\n",
    "\n",
    "norm_layer = torch.nn.BatchNorm1d(4)\n",
    "normed_tensor = norm_layer(my_tensor)\n",
    "print(norm_layer)\n",
    "print(normed_tensor.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9174, 0.0000, 0.4743, 0.1876],\n",
      "         [0.9854, 0.0000, 1.3405, 0.0000],\n",
      "         [0.0000, 1.4480, 0.0000, 0.4914],\n",
      "         [0.1861, 0.0000, 0.0000, 0.0000]]])\n",
      "tensor([[[0.9174, 1.7359, 0.0000, 0.1876],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4914],\n",
      "         [0.1861, 0.0000, 0.8889, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4)\n",
    "dropout = torch.nn.Dropout(p=0.4)\n",
    "print(dropout(my_tensor))\n",
    "print(dropout(my_tensor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
